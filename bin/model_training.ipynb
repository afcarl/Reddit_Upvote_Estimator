{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main\n",
    "from main import extract, transform, model\n",
    "import models\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Begin extract\n",
      "INFO:root:Downloading submissions from Reddit\n",
      "INFO:root:Beginning Reddit scraper, for subreddit: JapanTravel, and num_days: 1000\n",
      "INFO:root:Creating reddit connection\n",
      "INFO:root:Searching for subreddit: JapanTravel\n",
      "INFO:root:Completed scrape of subreddit: JapanTravel\n",
      "INFO:root:Found 16690 submissions\n",
      "INFO:root:Attempting to either validate or download and extract embeddings.\n",
      "INFO:root:Embeddings available at: ../resources/GoogleNews-vectors-negative300.bin\n",
      "INFO:root:Reading embedding matrix and word to index dictionary from file\n",
      "INFO:gensim.models.keyedvectors:loading projection weights from ../resources/GoogleNews-vectors-negative300.bin\n",
      "INFO:gensim.models.keyedvectors:loaded (3000000, 300) matrix from ../resources/GoogleNews-vectors-negative300.bin\n",
      "INFO:root:Created embedding matrix, of shape: (3000000, 300)\n",
      "INFO:root:Created word to index lookup, with min index: 0, max index: 2999999\n",
      "INFO:root:word_to_index max index: 2999999\n",
      "INFO:root:End extract\n",
      "INFO:root:Archiving data set schema(s) for step name: extract\n",
      "INFO:root:Working data_set: observations\n"
     ]
    }
   ],
   "source": [
    "# Extract\n",
    "embedding_matrix, word_to_index, observations = extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Begin transform\n",
      "INFO:root:Bin breakdown: \n",
      "10.000000     14830\n",
      "50.000000      1610\n",
      "100.000000      170\n",
      "inf              80\n",
      "Name: bin_max, dtype: int64\n",
      "INFO:root:End transform\n",
      "INFO:root:Archiving data set schema(s) for step name: transform\n",
      "INFO:root:Working data_set: observations\n"
     ]
    }
   ],
   "source": [
    "# Transform\n",
    "embedding_matrix, word_to_index, observations, label_encoder = transform(embedding_matrix, word_to_index, observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Begin model\n",
      "INFO:root:Archiving data set schema(s) for step name: model\n",
      "INFO:root:Working data_set: observations\n",
      "INFO:root:Proceeding w/ 13291 train observations, and 3399 test observations\n",
      "INFO:root:x_train shape: (13291, 100), y_train shape: (13291, 4), x_test shape: (3399, 100), y_test shape: (3399, 4)\n",
      "INFO:root:Creating and training model\n",
      "INFO:root:embedding_input_dim: 3000000, embedding_output_dim: 300, embedding_input_length: 100, output_shape: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13291 samples, validate on 3399 samples\n",
      "Epoch 1/5\n",
      "13291/13291 [==============================] - 14s 1ms/step - loss: 0.5307 - acc: 0.8467 - val_loss: 0.4443 - val_acc: 0.8926\n",
      "Epoch 2/5\n",
      "13291/13291 [==============================] - 14s 1ms/step - loss: 0.4005 - acc: 0.8876 - val_loss: 0.3816 - val_acc: 0.8929\n",
      "Epoch 3/5\n",
      "13291/13291 [==============================] - 10s 771us/step - loss: 0.3725 - acc: 0.8856 - val_loss: 0.3895 - val_acc: 0.8929\n",
      "Epoch 4/5\n",
      "13291/13291 [==============================] - 13s 990us/step - loss: 0.3389 - acc: 0.8908 - val_loss: 0.4067 - val_acc: 0.8929\n",
      "Epoch 5/5\n",
      "13291/13291 [==============================] - 10s 772us/step - loss: 0.2798 - acc: 0.9029 - val_loss: 0.4798 - val_acc: 0.8926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Finished creating and training model\n",
      "INFO:root:Archiving data set schema(s) for step name: transform\n",
      "INFO:root:Working data_set: observations\n",
      "INFO:root:End model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.000000     16409\n",
       "50.000000       158\n",
       "100.000000       96\n",
       "inf              27\n",
       "Name: modeling_prediction, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(models)\n",
    "reload(main)\n",
    "from main import model\n",
    "# Model\n",
    "embedding_matrix, word_to_index, observations, label_encoder, network = model(embedding_matrix, word_to_index, observations, label_encoder)\n",
    "\n",
    "observations['modeling_prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000     16409\n",
       "50.000000       158\n",
       "100.000000       96\n",
       "inf              27\n",
       "Name: modeling_prediction, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations['modeling_prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.000000     14830\n",
      "50.000000      1610\n",
      "100.000000      170\n",
      "inf              80\n",
      "Name: bin_max, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print observations['bin_max'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/JapanTravel/comments/2x8b5r/what_to_do_on_culture_day_nov_3/\n"
     ]
    }
   ],
   "source": [
    "print observations['url'].tolist()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
